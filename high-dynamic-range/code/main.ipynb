{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QupgVmcZgvyx"
   },
   "outputs": [],
   "source": [
    "## Created by Wentinn Liao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k722vkzdWafR"
   },
   "source": [
    "# CS180 Final Project: High Dynamic Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pbdKYaruWiD"
   },
   "outputs": [],
   "source": [
    "#@title Configure Jupyter Notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "uK2SmUy3uWiD",
    "outputId": "c1f1c997-17d2-4312-edf0-970abe258615"
   },
   "outputs": [],
   "source": [
    "#@title Library Setup\n",
    "import base64\n",
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage as sk\n",
    "import skimage.io as skio\n",
    "import cv2\n",
    "import torch\n",
    "from typing import *\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrE7RRVs886O"
   },
   "outputs": [],
   "source": [
    "#@title Utilities\n",
    "def read_image(imname: str) -> torch.Tensor:\n",
    "    return torch.IntTensor(skio.imread(imname))\n",
    "    # return sk.img_as_float(np.array(img.convert('RGBA')))\n",
    "\n",
    "def im_rescale(im):\n",
    "    lo = torch.min(im)\n",
    "    hi = torch.max(im)\n",
    "    return (im - lo) / (hi - lo)\n",
    "\n",
    "def im_saturate(im):\n",
    "    return torch.stack([im_rescale(im[:, :, c]) for c in range(im.shape[2])], dim=2)\n",
    "\n",
    "def multiply_outer(v: np.ndarray, arr: np.ndarray, axis=None):\n",
    "    if axis is None:\n",
    "        axis = v.ndim\n",
    "    arr_ = arr.transpose(*range(axis, arr.ndim), *range(axis))\n",
    "    return (arr_ * v).transpose(*range(arr.ndim - axis, arr.ndim), *range(arr.ndim - axis))\n",
    "\n",
    "def plot_cycle(ax, points: np.ndarray, **kwargs):\n",
    "    cycled_points = np.vstack([points, points[:1]])\n",
    "    ax.plot(*cycled_points.T, **kwargs)\n",
    "\n",
    "def show_video(video_name: str):\n",
    "    if os.path.exists(video_name):\n",
    "        video = io.open(video_name, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
    "            loop controls style=\"height: 400px;\">\n",
    "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "def color(z: float, scale: float=120.) -> np.ndarray:\n",
    "    k = 2 * np.pi * z / scale\n",
    "    return (1 + np.asarray([np.sin(k), np.sin(k + 2 * np.pi / 3), np.sin(k + 4 * np.pi / 3)], dtype=float)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "class Timer(object):\n",
    "    indent = 0\n",
    "    p = False\n",
    "\n",
    "    def __init__(self):\n",
    "        self.start_t = 0\n",
    "\n",
    "    def start(self, name):\n",
    "        if Timer.p:\n",
    "            print('\\t' * Timer.indent + name + ' {')\n",
    "            Timer.indent += 1\n",
    "        self.start_t = time.time_ns()\n",
    "\n",
    "    def stop(self):\n",
    "        if Timer.p:\n",
    "            Timer.indent -= 1\n",
    "            print('\\t' * Timer.indent + '} ' + f'{(time.time_ns() - self.start_t) * 1e-6}ms,')\n",
    "        # return time.time_ns() - self.start_t"
   ],
   "metadata": {
    "id": "07tXktty9tHn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1x42pGm7aOF"
   },
   "source": [
    "# Part 1. Radiance Map Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "im_dir = 'data/Memorial_SourceImages'\n",
    "ims, dts = [], []\n",
    "with open(f'{im_dir}/memorial.hdr_image_list.txt', 'r') as fp:\n",
    "    for line in fp.readlines()[3:13]:\n",
    "        fname, dt, _, _, _ = line.split()\n",
    "        ims.append(read_image(f'{im_dir}/{fname[:-4]}.png'))\n",
    "        dts.append(1 / float(dt))\n",
    "ims, dts = torch.stack(ims), torch.tensor(dts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(dts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for im in ims:\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def radiance_map(ims: torch.Tensor, dts: torch.Tensor, S: int=2048, l: float=10.):\n",
    "    w = torch.cat([torch.linspace(1, 128, 128), torch.linspace(128, 1, 128)]) ** 2\n",
    "    Z, P, height, width, _ = 256, *ims.shape\n",
    "    N = height * width\n",
    "\n",
    "    flattened_ims = ims.view(P, N, 3)\n",
    "    sampled_points = flattened_ims[:, torch.randint(0, N, (S,))].permute(2, 1, 0)           # [3 x S x P]\n",
    "\n",
    "    wi = w[sampled_points]                                                                  # [3 x S x P]\n",
    "    normalized_wi = wi / torch.sqrt(torch.sum(wi, dim=-1, keepdim=True))                    # [3 x S x P]\n",
    "    D = torch.diag_embed(wi) - normalized_wi[:, :, :, None] @ normalized_wi[:, :, None, :]  # [3 x S x P x P]\n",
    "\n",
    "    I = torch.eye(Z)                                                                        # [Z x Z]\n",
    "    I_ = I[sampled_points]                                                                  # [3 x S x P x Z]\n",
    "\n",
    "    W_ = I_.transpose(-2, -1) @ D                                                           # [3 x S x Z x P]\n",
    "    W = torch.mean(W_ @ I_, dim=1)                                                          # [3 x Z x Z]\n",
    "\n",
    "    G = l * torch.tensor([\n",
    "        [1., -2., 1.],\n",
    "        [-2., 4., -2.],\n",
    "        [1., -2., 1.]\n",
    "    ])\n",
    "    diag = torch.arange(Z - 2)\n",
    "    for i, j in itertools.product(range(3), range(3)):\n",
    "        W[:, i + diag, j + diag] += G[i, j] * w[1:-1]\n",
    "\n",
    "    ldts = torch.log(dts)\n",
    "    y = torch.mean(W_, dim=1) @ ldts[:, None]                                               # [3 x Z x 1]\n",
    "\n",
    "    g = (torch.inverse(W) @ y).squeeze(-1)                                                  # [3 x Z]\n",
    "    g -= (g[:, 127] + g[:, 128])[:, None] / 2\n",
    "\n",
    "    im_points = flattened_ims.permute(2, 1, 0).to(torch.int64)\n",
    "    K = torch.gather(g, -1, im_points.reshape(3, -1)).view(3, N, P) - ldts                  # [3 x N x P]\n",
    "    wi = torch.sqrt(w)[im_points]                                                           # [3 x N x P]\n",
    "    lE = (torch.sum(K * wi, dim=-1) / torch.sum(wi, dim=-1)).T.view(height, width, 3)\n",
    "\n",
    "    return g, torch.exp(lE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "g, E = radiance_map(ims, dts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for g_ in g:\n",
    "    plt.plot(g_)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2. Tone Mapping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def global_tone_map(im: torch.Tensor):\n",
    "    return im / (1 + im)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global_im = global_tone_map(E)\n",
    "\n",
    "plt.imshow(global_im)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def local_tone_map(im: torch.Tensor, dR: float=5.):\n",
    "    intensity = torch.mean(im, dim=-1, keepdim=True)\n",
    "    chrominance = im / intensity\n",
    "    L = torch.log(intensity)\n",
    "    B = torch.tensor(cv2.bilateralFilter(L.numpy(), 60, 240, 120))[:, :, None]\n",
    "    B_ = -dR * im_rescale(-B)\n",
    "    O = torch.exp((L - B) + B_)\n",
    "    return im_saturate((chrominance * O) ** 0.5)\n",
    "\n",
    "def adaptive_histogram(im: torch.Tensor, clipLimit: float=2., tileGridSize: Sequence[int]=(5, 5)):\n",
    "    im = sk.img_as_ubyte(im)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)\n",
    "    return torch.tensor(sk.img_as_float(torch.stack([torch.tensor(clahe.apply(im[:, :, c])) for c in range(3)], dim=-1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def hdr(ims: torch.Tensor, dts: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    g, E = radiance_map(ims, dts)\n",
    "    global_im = global_tone_map(E)\n",
    "    return {\n",
    "        'radiance_map': global_im,\n",
    "        'g': g,\n",
    "        'im': adaptive_histogram(global_im)\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "skio.imshow(sk.img_as_ubyte(hdr(ims, dts)['im']))\n",
    "skio.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_result(ims: torch.Tensor, dts: torch.Tensor, name: str):\n",
    "    hdr_result = hdr(ims, dts)\n",
    "\n",
    "    stacked_ims = torch.cat([\n",
    "        torch.cat([ims[0], ims[1]], dim=1),\n",
    "        torch.cat([ims[2], torch.IntTensor(sk.img_as_ubyte(hdr_result['im']))], dim=1)\n",
    "    ], dim=0)\n",
    "\n",
    "    skio.imsave(f'../images/{name}_radiance_map.png', sk.img_as_ubyte(hdr_result['radiance_map']))\n",
    "\n",
    "    plt.plot(hdr_result['g'][0], color='red')\n",
    "    plt.plot(hdr_result['g'][1], color='blue')\n",
    "    plt.plot(hdr_result['g'][2], color='green')\n",
    "    plt.title('Exposure Map')\n",
    "    plt.axis('on')\n",
    "    plt.savefig(f'../images/{name}_exposure_map.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "\n",
    "    skio.imsave(f'../images/{name}_hdr.png', sk.img_as_ubyte(stacked_ims))\n",
    "    plt.imshow(stacked_ims.numpy())\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "save_result(ims, dts, 'memorial')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20.0, 20.0)\n",
    "\n",
    "names = {\n",
    "    'data/Train0000_0210': [3, 51, 112, 193],\n",
    "    'data/Train0211_0420': [291, 343],\n",
    "    'data/Train0421_0625': [466, 575]\n",
    "}\n",
    "for dir_name, nums in names.items():\n",
    "    for i in nums:\n",
    "        s = str(i).zfill(4)\n",
    "        ims = torch.stack([\n",
    "            read_image(f'{dir_name}/{s}_short.png'),\n",
    "            read_image(f'{dir_name}/{s}_medium.png'),\n",
    "            read_image(f'{dir_name}/{s}_long.png')\n",
    "        ])\n",
    "        print(s)\n",
    "        dts = torch.pow(2, torch.FloatTensor(np.load(f'{dir_name}/{s}_exposures.npy')))\n",
    "        save_result(ims, dts, s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for dir_name, nums in names.items():\n",
    "    str_nums = {str(i).zfill(4) for i in nums}\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[:4] not in str_nums:\n",
    "            os.remove(f'{dir_name}/{fname}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "V100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}